{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:27:27.608045Z",
     "start_time": "2025-06-17T08:26:02.794918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import time\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "%capture"
   ],
   "id": "c1a6c2c0e6ff6f41",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "##  Feedforward Neural Networks (FNNs) for language models"
   ],
   "id": "26fc711cb1ebcbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "FNNs, or Multi-Layer Perceptrons, serve as the foundational components for comprehending neural networks in natural language processing (NLP). In NLP tasks, FNNs process textual data by transforming it into numerical vectors known as embeddings. Subsequently, these embeddings are input to the network to predict language facets, such as the upcoming word in a sentence or the sentiment of a text.\n",
    "\n",
    "Let's consider the following song lyrics for our analysis."
   ],
   "id": "ecc271569ccd8fde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:27:40.118933Z",
     "start_time": "2025-06-17T08:27:40.091310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "song= \"\"\"We are no strangers to love\n",
    "You know the rules and so do I\n",
    "A full commitments what Im thinking of\n",
    "You wouldnt get this from any other guy\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "And if you ask me how Im feeling\n",
    "Dont tell me youre too blind to see\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\"\"\""
   ],
   "id": "d0a36774369cf5e2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenization for FNN",
   "id": "c0f45b0d102c1434"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:00.491410Z",
     "start_time": "2025-06-17T08:28:00.480266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(song)"
   ],
   "id": "394c8265b1485062",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:02.715388Z",
     "start_time": "2025-06-17T08:28:02.696877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_string(s):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocesses a given string by performing the following steps:\n",
    "\n",
    "    1. Removes all non-word characters (excluding letters and numbers).\n",
    "    2. Removes all whitespace characters.\n",
    "    3. Removes all numeric digits.\n",
    "\n",
    "    Parameters:\n",
    "    s (str): The input string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    str: The processed string with only alphabetic characters, no spaces, and no digits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all non-word characters (everything except letters and numbers)\n",
    "    # \\w matches any word character (letters, numbers, and underscores)\n",
    "    # \\s matches any whitespace characters\n",
    "    # ^ inside [] negates the selection, so [^\\w\\s] matches anything  that's NOT a word character or whitespace.\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "\n",
    "    # Remove all whitespace characters (space, tabs, newlines)\n",
    "    # \\s+ matches one or more whitespaces characters\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "\n",
    "    # remove all digits (0, 9)\n",
    "    # \\d matches any digit character\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s"
   ],
   "id": "249338db1a08c009",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:06.997398Z",
     "start_time": "2025-06-17T08:28:06.139093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(words):\n",
    "    \"\"\"\n",
    "    Preprocesses a given text by tokenizing it, cleaning individual words, and\n",
    "    converting them to lowercase while removing empty or punctuation tokens.\n",
    "\n",
    "    Steps:\n",
    "    1. Tokenization: Splits the input text into individual word tokens.\n",
    "    2. Cleaning: Applies `preprocess_string()` to remove non-word characters,\n",
    "       spaces, and digits from each token.\n",
    "    3. Normalization: Converts all tokens to lowercase.\n",
    "    4. Filtering: Removes empty strings and punctuation tokens.\n",
    "\n",
    "    Parameters:\n",
    "    words (str): The input text to be tokenized and preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of cleaned, lowercase tokens.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text into words\n",
    "    tokens = word_tokenize(words)\n",
    "\n",
    "    # Apply preprocessing to each token(remove unwanted characters)\n",
    "    tokens = [preprocess_string(w) for w in tokens]\n",
    "\n",
    "    # Convert tokens to lowercase and remove empty strings or punctuations\n",
    "    return [w.lower() for w in tokens if len(w) != 0 and w not in string.punctuation]\n",
    "\n",
    "# Example usage:\n",
    "tokens = preprocess(song)"
   ],
   "id": "6a29d113061b2218",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Indexing",
   "id": "7fc9d17c25ae1d1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:20.610996Z",
     "start_time": "2025-06-17T08:28:20.475470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenizetext(song):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text (song) and builds a vocabulary from the tokens.\n",
    "\n",
    "    Steps:\n",
    "    1. Tokenization: The function splits the input text into words and applies\n",
    "       a tokenizer function to each word.\n",
    "    2. Vocabulary Building: Constructs a vocabulary from the tokenized words,\n",
    "       including a special \"<unk>\" token to handle out-of-vocabulary words.\n",
    "    3. Default Indexing: Sets the default index for unknown words, ensuring\n",
    "       that any unseen tokens are mapped to \"<unk>\".\n",
    "\n",
    "    Parameters:\n",
    "    song (str): The input text (song lyrics) to be tokenized and processed.\n",
    "\n",
    "    Returns:\n",
    "    vocab (Vocab): A vocabulary object mapping tokens to their corresponding indices.\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    # Split the input text into words and apply the tokenizer function to each word.\n",
    "    # The 'map' function ensures that each word is tokenized properly.\n",
    "\n",
    "    tokenized_song = map(tokenizer, song.split())\n",
    "\n",
    "    # Build vocabulary from tokenized text\n",
    "    # The function `build_vocab_from_iterator` constructs a vocabulary by iterating\n",
    "    # over the tokenized words. The special token \"<unk>\" is added to handle words\n",
    "    # that are not present in the vocabulary.\n",
    "\n",
    "    vocab = build_vocab_from_iterator(tokenized_song, specials=['<unk>'])\n",
    "\n",
    "     # Set the default index for unknown words\n",
    "    # The default index is set to the index of \"<unk>\" so that any word not found\n",
    "    # in the vocabulary is mapped to this token, preventing errors during lookup.\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "    return vocab"
   ],
   "id": "e3eef2b39ffbd442",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:25.464937Z",
     "start_time": "2025-06-17T08:28:24.804500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = tokenizetext(song)\n",
    "print(vocab(tokens[0: 10]))"
   ],
   "id": "584ce2cb78fb5fec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 58, 70, 74, 25, 69, 2, 20, 31, 72]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:48.881230Z",
     "start_time": "2025-06-17T08:28:48.866228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# text funct that converts raw text into indexes\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "print(text_pipeline(song)[0: 10])"
   ],
   "id": "652e11255e3fcb27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 58, 70, 74, 25, 69, 2, 20, 31, 72]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:28:51.414133Z",
     "start_time": "2025-06-17T08:28:51.401767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find the word corresponding to an index\n",
    "index_to_token = vocab.get_itos()\n",
    "print(index_to_token[58])"
   ],
   "id": "ba0347e60be78342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embedding Layers",
   "id": "c59faffcad05b0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "An embedding layer is a crucial element in natural language processing (NLP) and neural networks designed for sequential data. It serves to convert categorical variables, like words or discrete indexes representing tokens, into continuous vectors. This transformation facilitates training and enables the network to learn meaningful relationships among words.\n",
    "\n",
    "Let's consider a simple example involving a vocabulary of words\n",
    "\n",
    "Vocabulary: {apple, banana, orange, pear}\n",
    "Each word in your vocabulary has a unique index assigned to it:\n",
    "\n",
    "Indices: {0, 1, 2, 3}\n",
    "When using an embedding layer, you will initialize random continuous vectors for each index. For instance, the embedding vectors might look like:\n",
    "\n",
    "Vector for index 0 (apple): [0.2, 0.8]\n",
    "Vector for index 1 (banana): [0.6, -0.5]\n",
    "Vector for index 2 (orange): [-0.3, 0.7]\n",
    "Vector for index 3 (pear): [0.1, 0.4] In PyTorch, you can create an embedding layer."
   ],
   "id": "371932072c3e7d2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:29:05.891398Z",
     "start_time": "2025-06-17T08:29:05.877373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def genembedding(vocab):\n",
    "    \"\"\"\n",
    "    Generates an embedding layer for the given vocabulary.\n",
    "\n",
    "    The embedding layer transforms words into dense vector representations,\n",
    "    allowing the model to learn semantic relationships between words.\n",
    "\n",
    "    Parameters:\n",
    "    vocab (Vocab): The vocabulary object containing unique words and their indices.\n",
    "\n",
    "    Returns:\n",
    "    nn.Embedding: A PyTorch embedding layer with a specified embedding dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the embedding dimensions (size of word vectors)\n",
    "    embedding_dim = 20  # Each word will be represented as a 20-dimensional vector\n",
    "\n",
    "    # Get the vocabulary size (number of unique words in the vocabulary)\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    # Create the embedding layer\n",
    "     # The nn.Embedding module maps word indices to dense vector representations.\n",
    "    # It takes vocab_size as the number of words and embedding_dim as the vector size.\n",
    "\n",
    "    embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    return embeddings"
   ],
   "id": "2d6d8fbf1e723a88",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generating context-target pairs (n-grams)",
   "id": "25f7cfb8d39fc0e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Organize words within a variable-size context using the following approach: Each word is denoted by 'i'. To establish the context, simply subtract 'j'. The size of the context is determined by the value ofCONTEXT_SIZE.",
   "id": "564eac0ec44146b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:29:10.097610Z",
     "start_time": "2025-06-17T08:29:10.080489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the context size for generating n-grams\n",
    "CONTEXT_SIZE = 2 # The number of previous words used to predict the next word\n",
    "\n",
    "def genngrams(tokens):\n",
    "    \"\"\"\n",
    "    Generates n-grams from a list of tokens, where each n-gram consists of a\n",
    "    context (previous words) and a target (next word).\n",
    "\n",
    "    The function constructs a list of tuples where:\n",
    "    - The first element is a list of `CONTEXT_SIZE` previous words.\n",
    "    - The second element is the target word that follows the context.\n",
    "\n",
    "    Parameters:\n",
    "    tokens (list): A list of preprocessed word tokens.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples representing n-grams.\n",
    "          Each tuple contains (context_words, target_word).\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate n-grams\n",
    "    # Iterate through the tokens starting from index CONTEXT_SIZE to the end\n",
    "    # For each token at position 'i', extract the previous CONTEXT_SIZE words as context\n",
    "\n",
    "    ngrams = [\n",
    "        (\n",
    "            [tokens[i - j - 1] for j in range(CONTEXT_SIZE)], # Context words\n",
    "            tokens[i] # Target word(the word to predict)\n",
    "        )\n",
    "        for i in range(CONTEXT_SIZE, len(tokens))\n",
    "    ]\n",
    "\n",
    "    return ngrams"
   ],
   "id": "d064a076fe9c7e75",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:29:13.313196Z",
     "start_time": "2025-06-17T08:29:13.295224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ngrams = genngrams(tokens)\n",
    "context, target = ngrams[0]\n",
    "print(\"Context\", context, \"target\", target)\n",
    "print(\"context index\", vocab(context), \"target index\", vocab([target]))"
   ],
   "id": "dd8f0928531ccdcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context ['are', 'we'] target no\n",
      "context index [58, 21] target index [70]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:30:06.891100Z",
     "start_time": "2025-06-17T08:30:06.877725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim = 20\n",
    "linear = nn.Linear(embedding_dim*CONTEXT_SIZE, 128)"
   ],
   "id": "6610220a832fc1fd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:30:52.341716Z",
     "start_time": "2025-06-17T08:30:52.289021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = genembedding(vocab)\n",
    "my_embeddings = embeddings(torch.tensor(vocab(context)))\n",
    "print(my_embeddings.shape)"
   ],
   "id": "575f666aac1faefc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:31:11.619119Z",
     "start_time": "2025-06-17T08:31:00.078337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# they can be used as inputs in the next layer\n",
    "linear(my_embeddings)"
   ],
   "id": "93a1ffd46417d594",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x20 and 40x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# they can be used as inputs in the next layer\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmy_embeddings\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (2x20 and 40x128)"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Batch function",
   "id": "64cfcfdfd5cd2fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "wCreate a Batch function to interface with the data loader. Several adjustments are necessary to handle words that are part of a context in one batch and a predicted word in the following batch.",
   "id": "7b74e1b5a31cdac4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:37:40.682965Z",
     "start_time": "2025-06-17T08:37:40.658033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader # for batch production\n",
    "import torch\n",
    "\n",
    "# Set the devices to GPU if available; otherwise, use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the hyperparameters\n",
    "CONTEXT_SIZE = 3 # number of previous words used as context for prediction\n",
    "BATCH_SIZE = 10 # Number of samples per training batch\n",
    "EMBEDDING_DIM = 10 # Dimension of words embeddings\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    Processes a batch of text data into input (context) and output (target) tensors\n",
    "    for training a language model.\n",
    "\n",
    "    The function extracts:\n",
    "    - `context`: A list of word indices representing the context words for each target word.\n",
    "    - `target`: A list of word indices representing the target word to predict.\n",
    "\n",
    "    Parameters:\n",
    "    batch (list): A list of tokenized words (strings).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Two PyTorch tensors: (context_tensor, target_tensor)\n",
    "           - context_tensor: Tensor of shape (batch_size - CONTEXT_SIZE, CONTEXT_SIZE),\n",
    "             containing the word indices of context words.\n",
    "           - target_tensor: Tensor of shape (batch_size - CONTEXT_SIZE,),\n",
    "             containing the word indices of target words.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(batch) # Get the size of the batch\n",
    "    context, target = [], [] # Initialize lists for context and target word\n",
    "\n",
    "    # Loop through the batch, ensuring enough previous words exist for context\n",
    "\n",
    "    for i in range(CONTEXT_SIZE, batch_size):\n",
    "        # Convert the target word to index using the vocabulary\n",
    "        target.append(vocab([batch[i]]))\n",
    "\n",
    "        # Convert the previous CONTEXT_SIZE words to indices using the vocabulary\n",
    "        context.append((vocab([batch[i - j - 1] for j in range(CONTEXT_SIZE)])))\n",
    "\n",
    "    # Convert lists to PyTorch tensors and move them to the appropriate device\n",
    "    return torch.tensor(context).to(device), torch.tensor(target).to(device).reshape(-1)"
   ],
   "id": "2773399a685e584b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Similarly, it's important to highlight that the size of the last batch could deviate from that of the earlier batches. To tackle this, the approach involves adjusting the final batch to conform to the specified batch size, ensuring it becomes a multiple of the predetermined size. When necessary, you'll employ padding techniques to achieve this harmonization. One approach you'll use is appending the beginning of the song to the end of the batch."
   ],
   "id": "1d15adda6c01fe1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:16.931326Z",
     "start_time": "2025-06-17T08:38:16.920521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Padding = BATCH_SIZE-len(tokens)%BATCH_SIZE\n",
    "tokens_pad = tokens + tokens[0: Padding]"
   ],
   "id": "523a369346c3c19c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the DataLoader",
   "id": "af587acaf92ade9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:18.469699Z",
     "start_time": "2025-06-17T08:38:18.454605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(\n",
    "    tokens_pad,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ],
   "id": "9ff7e10f8023259e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Multi-class neural network"
   ],
   "id": "70d9ea54f8514c9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You have developed a PyTorch class for a multi-class neural network. The network's output is the probability of the next word within a given context. Therefore, the number of classes corresponds to the count of distinct words. The initial layer consists of embeddings, and in addition to the final layer, an extra hidden layer is incorporated.",
   "id": "a914efe503b9aa7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:37:54.751361Z",
     "start_time": "2025-06-17T08:37:54.717634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network-based n-gram language model that predicts the next word\n",
    "    given a sequence of context words.\n",
    "\n",
    "    This model consists of:\n",
    "    - An embedding layer that converts word indices into dense vector representations.\n",
    "    - A fully connected hidden layer with ReLU activation.\n",
    "    - An output layer that predicts the probability distribution over the vocabulary.\n",
    "\n",
    "    Parameters:\n",
    "    vocab_size (int): The number of unique words in the vocabulary.\n",
    "    embedding_dim (int): The size of the word embeddings (vector representation of words).\n",
    "    context_size (int): The number of previous words used as context to predict the next word.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "\n",
    "        # Store context size and embedding dimension\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Embedding layer: Maps word indices to dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Fully connected hidden layer: Maps the concatenated embeddings to a 128-dimensional space\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "\n",
    "        # Output layer: Maps the hidden layer output to vocabulary size (probability distribution over words)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Parameters:\n",
    "        inputs (Tensor): A tensor of shape (batch_size, context_size) containing word indices.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: A tensor of shape (batch_size, vocab_size) representing predicted probabilities for the next word.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert input words indices into dense vectors using the embedding layer\n",
    "\n",
    "        embeds = self.embedding(inputs) # Shape: (batch_size, context_size, embedding_dim)\n",
    "\n",
    "        # Reshape the embeddings into a single vector per input sample\n",
    "        embeds = torch.reshape(embeds, (-1, self.context_size * self.embedding_dim))\n",
    "        # New shape: (batch_size, context_size * embedding_dim)\n",
    "\n",
    "        # Apply first fully connected layer with ReLU activation\n",
    "        out = F.relu(self.linear1(embeds)) # Shape: (batch_size, 128)\n",
    "\n",
    "        # Apply second fully connected layer to generate vocabulary-size logits\n",
    "        out = self.linear2(out) # Shape: (batch_size, vocab_size)\n",
    "\n",
    "        return out"
   ],
   "id": "febcde5e4a58d40",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a model",
   "id": "9beae86718780a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:01.584702Z",
     "start_time": "2025-06-17T08:38:01.564804Z"
    }
   },
   "cell_type": "code",
   "source": "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE).to(device)",
   "id": "b0b7bdf9087d77f9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrieve samples from the data loader object and input them into the neural network.",
   "id": "6971108605f9e7ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:23.458685Z",
     "start_time": "2025-06-17T08:38:23.307008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context, target = next(iter(dataloader))\n",
    "print(context, target)\n",
    "out = model(context)"
   ],
   "id": "edf89fd7d0409ed1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[70, 58, 21],\n",
      "        [74, 70, 58],\n",
      "        [25, 74, 70],\n",
      "        [69, 25, 74],\n",
      "        [ 2, 69, 25],\n",
      "        [20,  2, 69],\n",
      "        [31, 20,  2]]) tensor([74, 25, 69,  2, 20, 31, 72])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:30.896013Z",
     "start_time": "2025-06-17T08:38:30.885317Z"
    }
   },
   "cell_type": "code",
   "source": "print(out.shape)",
   "id": "d386fd508757c8cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 79])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Find the index with the highest probability."
   ],
   "id": "45c80a811e06f536"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:37.207140Z",
     "start_time": "2025-06-17T08:38:37.184829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predicted_index = torch.argmax(out, 1)\n",
    "print(predicted_index)"
   ],
   "id": "54cafc8548d94cab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 63, 73, 37, 63, 63, 63])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find the corresponding token.",
   "id": "6bc2794e170fffce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:41.192822Z",
     "start_time": "2025-06-17T08:38:41.165761Z"
    }
   },
   "cell_type": "code",
   "source": "[index_to_token[i.item()] for i in predicted_index]",
   "id": "460562e9bb533773",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desert', 'dont', 'see', 'each', 'dont', 'dont', 'dont']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:49.397879Z",
     "start_time": "2025-06-17T08:38:49.374699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_song(model, my_song, number_of_words=100):\n",
    "    \"\"\"\n",
    "    Generates text using a trained n-gram language model.\n",
    "\n",
    "    Given an initial text (`my_song`), the function generates additional words by\n",
    "    predicting the next word iteratively based on the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): The trained n-gram language model.\n",
    "    my_song (str): The initial seed text to start generating words.\n",
    "    number_of_words (int): The number of words to generate (default: 100).\n",
    "\n",
    "    Returns:\n",
    "    str: The generated song lyrics as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the mapping from index to word for decoding predictions\n",
    "    index_to_token = vocab.get_itos()\n",
    "\n",
    "    # Loop to generate the desired number of words\n",
    "    for i in range(number_of_words):\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for inference\n",
    "\n",
    "            # Prepare the input context by extracting the last CONTEXT_SIZE words from tokens\n",
    "            context = torch.tensor(\n",
    "                vocab([tokens[i - j - 1] for j in range(CONTEXT_SIZE)])\n",
    "            ).to(device)  # Move to CPU/GPU as required\n",
    "\n",
    "            # Predict the next word by selecting the word with the highest probability\n",
    "            word_idx = torch.argmax(model(context))  # Get index of the most likely next word\n",
    "\n",
    "            # Append the predicted word to the generated text\n",
    "            my_song += \" \" + index_to_token[word_idx.detach().item()]\n",
    "\n",
    "    return my_song  # Return the generated lyrics\n"
   ],
   "id": "56bd5837d1116da",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:38:52.834543Z",
     "start_time": "2025-06-17T08:38:52.592708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pickrandomline(song):\n",
    "    \"\"\"\n",
    "    Selects a random line from the given song text.\n",
    "\n",
    "    This function splits the song into separate lines and randomly picks one of them.\n",
    "\n",
    "    Parameters:\n",
    "    song (str): The song lyrics as a multi-line string.\n",
    "\n",
    "    Returns:\n",
    "    str: A randomly selected line from the song.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the song into individual lines\n",
    "    lines = song.split(\"\\n\")\n",
    "\n",
    "    # Randomly select a line and remove leading/trailing whitespace\n",
    "    selected_line = random.choice(lines).strip()\n",
    "\n",
    "    return selected_line  # Return the randomly selected line\n",
    "\n",
    "# Example usage:\n",
    "selected_line = pickrandomline(song)  # Pick a random line from the song\n",
    "\n",
    "# Generate a new song starting with the selected line\n",
    "generated_song = write_song(model, selected_line)\n",
    "\n",
    "# Print the generated lyrics\n",
    "print(generated_song)\n"
   ],
   "id": "7b5dfc9690a1b9de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never gonna tell a lie and hurt you dont you give desert dont see each dont dont dont dont ask let dont let dont if see see let you so dont if blind let let too dont let dont see let dont your dont weve dont let dont <unk> dont dont weve never we dont dont dont give dont we dont dont your let say give dont dont dont ask <unk> each rules gonna dont dont dont dont dont we dont dont dont dont we dont your say weve down your dont how gonna <unk> dont so dont if dont dont weve long dont dont dont dont dont\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "85b819d8908d401a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Training a language model involves a multi-step process that leverages training and testing data to optimize model performance. In the realm of Natural Language Processing (NLP), this process often employs various metrics to gauge a model's accuracy, such as perplexity or accuracy on unseen data. However, in the context of your current exploration, you will embark on a slightly different journey. Instead of relying solely on conventional NLP metrics, the focus shifts to manual inspection of the results.\n",
    "\n",
    "You have the cross entropy loss between input logits and target:"
   ],
   "id": "ad1dcad2d046f48f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:39:03.691032Z",
     "start_time": "2025-06-17T08:39:03.678448Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = torch.nn.CrossEntropyLoss()",
   "id": "52f8c5e9ba5d7483",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:39:14.893456Z",
     "start_time": "2025-06-17T08:39:05.628535Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = optim.SGD(model.parameters(), lr=0.01)",
   "id": "a740cb4e3662a6be",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "You have developed a function dedicated to training the model using the supplied data loader. In addition to training the model, the function's output includes predictions for each epoch, spanning context for the next 100 words."
   ],
   "id": "30af6e03c1538f13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:39:36.565592Z",
     "start_time": "2025-06-17T08:39:36.542747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(dataloader, model,song,number_of_epochs=100, show=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dataloader (DataLoader): DataLoader containing training data.\n",
    "        model (nn.Module): Neural network model to be trained.\n",
    "        number_of_epochs (int, optional): Number of epochs for training. Default is 100.\n",
    "        show (int, optional): Interval for displaying progress. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        list: List containing loss values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    MY_LOSS = []  # List to store loss values for each epoch\n",
    "\n",
    "    # Iterate over the specified number of epochs\n",
    "    for epoch in tqdm(range(number_of_epochs)):\n",
    "        total_loss = 0  # Initialize total loss for the current epoch\n",
    "        my_song = \"\"    # Initialize a string to store the generated song\n",
    "\n",
    "        # Iterate over batches in the dataloader\n",
    "        for context, target in dataloader:\n",
    "            model.zero_grad()          # Zero the gradients to avoid accumulation\n",
    "            predicted = model(context)  # Forward pass through the model to get predictions\n",
    "            loss = criterion(predicted, target.reshape(-1))  # Calculate the loss\n",
    "            total_loss += loss.item()   # Accumulate the loss\n",
    "\n",
    "            loss.backward()    # Backpropagation to compute gradients\n",
    "            optimizer.step()   # Update model parameters using the optimizer\n",
    "\n",
    "        # Display progress and generate song at specified intervals\n",
    "        if epoch % show == 0:\n",
    "            selected_line=pickrandomline(song)\n",
    "            my_song += write_song(model, selected_line)    # Generate song using the model\n",
    "\n",
    "            print(\"Generated Song:\")\n",
    "            print(\"\\n\")\n",
    "            print(my_song)\n",
    "\n",
    "        MY_LOSS.append(total_loss/len(dataloader))  # Append the total loss for the epoch to MY_LOSS list\n",
    "\n",
    "    return MY_LOSS  # Return the list of  mean loss values for each epoch"
   ],
   "id": "bf4cee245cd0e5e3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:39:38.280869Z",
     "start_time": "2025-06-17T08:39:38.269897Z"
    }
   },
   "cell_type": "code",
   "source": "my_loss_list=[]",
   "id": "9015a90e6f4c7cdd",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:39:44.001474Z",
     "start_time": "2025-06-17T08:39:43.980875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the context size for the n-gram model\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "# Create an instance of the NGramLanguageModeler class with specified parameters\n",
    "model_2 = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
    "\n",
    "# Define the optimizer for training the model, using stochastic gradient descent (SGD)\n",
    "optimizer = optim.SGD(model_2.parameters(), lr=0.01)\n",
    "\n",
    "# Set up a learning rate scheduler using StepLR to adjust the learning rate during training\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1.0, gamma=0.1)"
   ],
   "id": "cf581011055257f3",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:42:08.665459Z",
     "start_time": "2025-06-17T08:40:16.499434Z"
    }
   },
   "cell_type": "code",
   "source": "my_loss=train(dataloader,model_2,song)",
   "id": "59ce5cef3674276e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                             | 1/100 [00:01<01:44,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Weve known each other for so long <unk> <unk> <unk> <unk> <unk> never what <unk> <unk> you never <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> commitments <unk> never <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> you <unk> <unk> <unk> <unk> <unk> feeling <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> you <unk> <unk> <unk> <unk> <unk> <unk> <unk> never <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> you <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> run how never\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▉                                        | 11/100 [00:12<02:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna make you cry <unk> never <unk> never never <unk> <unk> never never never <unk> never you you never never never <unk> <unk> <unk> <unk> never never <unk> you <unk> <unk> you <unk> never never <unk> <unk> <unk> you never <unk> <unk> <unk> <unk> <unk> you never <unk> <unk> <unk> <unk> you <unk> never <unk> <unk> <unk> you never never <unk> <unk> <unk> you and you you never <unk> <unk> <unk> you never you <unk> <unk> <unk> you never <unk> <unk> <unk> you never and you you <unk> you never <unk> <unk> never <unk> you <unk> <unk> you <unk> <unk> <unk> you never <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                   | 21/100 [00:24<01:13,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna let you down never never never never never <unk> <unk> never never never <unk> hurt you you never never and <unk> never feeling <unk> never never <unk> you <unk> <unk> you <unk> never never <unk> <unk> tell you never <unk> feeling <unk> <unk> tell you never never <unk> <unk> tell you never never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you never never <unk> <unk> tell goodbye never <unk> <unk> tell you never and hurt you never never never <unk> <unk> never and you <unk> <unk> never <unk> <unk> <unk> goodbye never <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████▉                               | 31/100 [00:40<02:22,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna run around and desert you never never never never never <unk> and never never never <unk> hurt you you never never and <unk> im feeling <unk> never never never you <unk> <unk> you down never never <unk> <unk> tell you never <unk> feeling <unk> <unk> tell you down never <unk> <unk> tell you never never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you down never <unk> <unk> tell goodbye never <unk> <unk> tell you never and hurt you never never each <unk> <unk> never and you <unk> and never <unk> <unk> <unk> goodbye never <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████▍                          | 41/100 [00:53<01:14,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna give you up never never no never never <unk> and never never never <unk> hurt you you never never and <unk> im feeling <unk> never never never you <unk> <unk> never down never never <unk> <unk> tell you how im feeling <unk> <unk> tell you down never <unk> <unk> tell you never never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you down never <unk> <unk> tell goodbye never <unk> <unk> tell you never and hurt you never never each other for never and you goodbye been aching <unk> <unk> <unk> goodbye to <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████▉                      | 51/100 [01:02<00:43,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna make you cry never never no strangers never know and never never never <unk> hurt you you never never and <unk> im feeling <unk> never never never you <unk> how never how never never <unk> <unk> tell you how im feeling <unk> <unk> tell you down never <unk> <unk> tell you never never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you down never <unk> <unk> tell goodbye never <unk> <unk> tell you how and hurt you never known each other for never and you other been aching but <unk> too shy to <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████▍                 | 61/100 [01:12<00:44,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Inside we both know whats been going on never never no strangers to know and never the game and hurt you you to full and <unk> im feeling <unk> know never never been <unk> how never how never never <unk> <unk> tell you how im feeling <unk> <unk> tell you down never <unk> <unk> tell you never never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you down never <unk> <unk> tell goodbye never <unk> <unk> tell you how and hurt you never known each other for never and you other been aching but youre too shy to <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████▉             | 71/100 [01:24<00:32,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna say goodbye never never no strangers to know you never the game and hurt you you to full commitments <unk> im feeling to know never never been <unk> how never how never never <unk> <unk> tell you how im feeling <unk> <unk> tell you understand never <unk> <unk> tell you never never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you understand never <unk> <unk> tell goodbye never <unk> <unk> tell you how and hurt you never known each other for never and you other been aching but youre too shy to <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████▍        | 81/100 [01:32<00:16,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna run around and desert you never never no strangers to know you know the game and hurt you you to full commitments <unk> im feeling to know never never been <unk> how other how i never <unk> <unk> tell you how im feeling <unk> <unk> tell you understand never <unk> <unk> tell you up never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you understand never <unk> <unk> tell goodbye never <unk> <unk> tell you how and hurt you never known each other for never and you other been aching but youre too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████▉    | 91/100 [01:42<00:08,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "I just wanna tell you how Im feeling never never no strangers to know you know the game and hurt you i to full commitments <unk> im feeling to know never get been from how other guy i never <unk> <unk> tell you how im feeling <unk> <unk> tell you understand never <unk> <unk> tell you up never <unk> <unk> tell you down never <unk> <unk> tell you and desert you never <unk> <unk> tell you understand never <unk> <unk> tell goodbye never <unk> <unk> tell you how and hurt you never known each other for never and you hearts been aching but youre too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 100/100 [01:51<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the model",
   "id": "3258ef4dbc9bff88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:42:54.864583Z",
     "start_time": "2025-06-17T08:42:54.718767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = '2gram.pth'\n",
    "torch.save(model_2.state_dict(), save_path)\n",
    "my_loss_list.append(my_loss)"
   ],
   "id": "5b476c35933ec0f9",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The code provided below shows word embeddings from the created model, reduces their dimensionality to 2D using t-SNE, and then plots them as a scatter plot. Additionally, it annotates the first 20 points in the visualization with their corresponding words. This is used to visualize how similar words cluster together in a lower-dimensional space, revealing the structure of the word embeddings. Embeddings allow the model to represent words in a continuous vector space, capturing semantic relationships and similarities between words.\n",
    "\n"
   ],
   "id": "936f0929e7075ac0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:44:03.703855Z",
     "start_time": "2025-06-17T08:43:53.884071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = model_2.embedding.weight.cpu().detach().numpy()\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "labels = []\n",
    "\n",
    "for j in range(len(X_2d)):\n",
    "    if j < 20:\n",
    "        plt.scatter(X_2d[j, 0], X_2d[j, 1], label=index_to_token[j])\n",
    "        labels.append(index_to_token[j])\n",
    "        # Add words as annotations\n",
    "        plt.annotate(index_to_token[j],\n",
    "                     (X_2d[j, 0], X_2d[j, 1]),\n",
    "                     textcoords=\"offset points\",\n",
    "                     xytext=(0, 10),\n",
    "                     ha='center')\n",
    "    else:\n",
    "        plt.scatter(X_2d[j, 0], X_2d[j, 1])\n",
    "\n",
    "plt.legend(labels, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ],
   "id": "42684ea5d13e59ed",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[42]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m X = model_2.embedding.weight.cpu().detach()\n\u001B[32m      2\u001B[39m tsne = TSNE(n_components=\u001B[32m2\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m X_2d = \u001B[43mtsne\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m labels = []\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X_2d)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    317\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    318\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    319\u001B[39m         return_tuple = (\n\u001B[32m    320\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    321\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    322\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py:1363\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1356\u001B[39m     estimator._validate_params()\n\u001B[32m   1358\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1359\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1360\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1361\u001B[39m     )\n\u001B[32m   1362\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1363\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1144\u001B[39m, in \u001B[36mTSNE.fit_transform\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m   1123\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001B[39;00m\n\u001B[32m   1124\u001B[39m \n\u001B[32m   1125\u001B[39m \u001B[33;03mParameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1141\u001B[39m \u001B[33;03m    Embedding of the training data in low-dimensional space.\u001B[39;00m\n\u001B[32m   1142\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1143\u001B[39m \u001B[38;5;28mself\u001B[39m._check_params_vs_input(X)\n\u001B[32m-> \u001B[39m\u001B[32m1144\u001B[39m embedding = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1145\u001B[39m \u001B[38;5;28mself\u001B[39m.embedding_ = embedding\n\u001B[32m   1146\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.embedding_\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:870\u001B[39m, in \u001B[36mTSNE._fit\u001B[39m\u001B[34m(self, X, skip_num_points)\u001B[39m\n\u001B[32m    867\u001B[39m     \u001B[38;5;28mself\u001B[39m.learning_rate_ = \u001B[38;5;28mself\u001B[39m.learning_rate\n\u001B[32m    869\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.method == \u001B[33m\"\u001B[39m\u001B[33mbarnes_hut\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m870\u001B[39m     X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    871\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    872\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    873\u001B[39m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m        \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat64\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    878\u001B[39m     X = validate_data(\n\u001B[32m    879\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    880\u001B[39m         X,\n\u001B[32m    881\u001B[39m         accept_sparse=[\u001B[33m\"\u001B[39m\u001B[33mcsr\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcsc\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcoo\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    882\u001B[39m         dtype=[np.float32, np.float64],\n\u001B[32m    883\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2952\u001B[39m         out = X, y\n\u001B[32m   2953\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2954\u001B[39m     out = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2955\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2956\u001B[39m     out = _check_y(y, **check_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1053\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1051\u001B[39m         array = xp.astype(array, dtype, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1052\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1053\u001B[39m         array = \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1054\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[32m   1055\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1056\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.format(array)\n\u001B[32m   1057\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcomplex_warning\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:757\u001B[39m, in \u001B[36m_asarray_with_order\u001B[39m\u001B[34m(array, dtype, order, copy, xp, device)\u001B[39m\n\u001B[32m    755\u001B[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001B[32m    756\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m     array = \u001B[43mnumpy\u001B[49m\u001B[43m.\u001B[49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    759\u001B[39m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[32m    760\u001B[39m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[32m    761\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m xp.asarray(array)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\GenAI&NLP\\.venv\\Lib\\site-packages\\torch\\_tensor.py:1064\u001B[39m, in \u001B[36mTensor.__array__\u001B[39m\u001B[34m(self, dtype)\u001B[39m\n\u001B[32m   1062\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.numpy()\n\u001B[32m   1063\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m.astype(dtype, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[31mRuntimeError\u001B[39m: Numpy is not available"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, for a context of eight.",
   "id": "fc5a9d202a20db7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T08:47:45.094902Z",
     "start_time": "2025-06-17T08:44:25.981850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONTEXT_SIZE=8\n",
    "model_8 = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
    "optimizer = optim.SGD(model_8.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "my_loss=train(dataloader,model_8,song)\n",
    "\n",
    "save_path = '8gram.pth'\n",
    "torch.save(model_8.state_dict(), save_path)\n",
    "\n",
    "my_loss_list.append(my_loss)"
   ],
   "id": "35a7b0155611a5c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                             | 1/100 [00:06<11:32,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna give you up <unk> <unk> for just <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> lie <unk> <unk> <unk> <unk> <unk> cry <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> you <unk> <unk> <unk> <unk> <unk> <unk> make you around <unk> <unk> <unk> <unk> you <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> feeling <unk> <unk> <unk> around <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▉                                        | 11/100 [00:28<05:09,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "We know the game and were gonna play it <unk> <unk> <unk> strangers to <unk> <unk> <unk> the <unk> <unk> tell <unk> <unk> <unk> you <unk> make im thinking never <unk> <unk> make <unk> you <unk> never <unk> i <unk> <unk> <unk> give you you never <unk> <unk> <unk> give you you never <unk> <unk> give you cry never <unk> <unk> give you you <unk> <unk> <unk> give you you never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you never <unk> <unk> tell you lie <unk> <unk> tell <unk> <unk> <unk> give for so <unk> you <unk> <unk> <unk> <unk> <unk> <unk> shy to <unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                   | 21/100 [00:49<03:11,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "We know the game and were gonna play it <unk> <unk> to strangers to to <unk> <unk> the rules <unk> tell make <unk> <unk> it and give im thinking never <unk> tell make <unk> me on im guy i <unk> <unk> <unk> give you im im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> give you up never <unk> <unk> run around im never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you cry never <unk> tell a lie never <unk> tell <unk> <unk> tell other for so long im feeling <unk> <unk> to <unk> too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████▉                               | 31/100 [01:05<02:18,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Gotta make you understand <unk> <unk> to strangers to to feeling <unk> the rules <unk> tell make <unk> <unk> it and give im thinking never <unk> tell for <unk> me on so guy i <unk> the <unk> give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> give around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> tell <unk> <unk> give other for so long im feeling <unk> <unk> a <unk> too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████▍                          | 41/100 [01:24<03:16,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna run around and desert you <unk> <unk> to strangers to so feeling <unk> the rules <unk> tell make <unk> i it and give im thinking never <unk> tell for <unk> me on so guy i <unk> the <unk> give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> give around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> tell <unk> <unk> give other for so long im feeling <unk> <unk> thinking <unk> too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████▉                      | 51/100 [01:51<02:58,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna tell a lie and hurt you <unk> <unk> to strangers to so feeling <unk> the rules <unk> tell make <unk> i it and give im thinking never <unk> tell for tell me on so guy i <unk> the me give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> run around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> tell <unk> <unk> give other for so long im feeling <unk> <unk> thinking going too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████▍                 | 61/100 [02:09<01:26,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Your hearts been aching but youre too shy to say it <unk> <unk> to strangers to so feeling <unk> the rules rules tell make <unk> i it and give im thinking never <unk> tell for tell me on so guy i <unk> the me give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> run around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> tell <unk> <unk> give other for so long im feeling <unk> <unk> thinking going too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████▉             | 71/100 [02:28<01:28,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "We know the game and were gonna play it <unk> <unk> to strangers to so feeling we the rules rules tell make <unk> i it and give im thinking never <unk> tell for tell me on so guy i <unk> the me give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> run around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> <unk> <unk> <unk> give other for so long im feeling <unk> <unk> thinking going too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████▍        | 81/100 [02:42<00:33,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna say goodbye <unk> <unk> to strangers to so feeling we the rules rules tell make <unk> i it and give im thinking never <unk> tell so tell me on so guy i <unk> the me give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> run around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> <unk> <unk> <unk> give other for so long im feeling <unk> <unk> thinking going too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████▉    | 91/100 [03:01<00:20,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Song:\n",
      "\n",
      "\n",
      "Never gonna say goodbye <unk> <unk> to strangers to so feeling we the rules rules tell make <unk> i it and give im thinking never <unk> tell so tell me on so guy i <unk> the me give you up im feeling <unk> <unk> give you cry never <unk> <unk> give you up never <unk> <unk> run around up never <unk> <unk> run around up never <unk> <unk> <unk> <unk> make you cry never <unk> <unk> give you up never <unk> tell a lie never <unk> <unk> <unk> <unk> give other for so long im feeling <unk> <unk> thinking going too shy to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 100/100 [03:16<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The code provided below shows word embeddings from the created model, reduces their dimensionality to 2D using t-SNE, and then plots them as a scatter plot. Additionally, it annotates the first 20 points in the visualization with their corresponding words. This is used to visualize how similar words cluster together in a lower-dimensional space, revealing the structure of the word embeddings. Embeddings allow the model to represent words in a continuous vector space, capturing semantic relationships and similarities between words.\n",
    "\n"
   ],
   "id": "3b0c9a8fac239a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = model_8.embeddings.weight.cpu().detach().numpy()\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "labels = []\n",
    "\n",
    "for j in range(len(X_2d)):\n",
    "    if j < 20:\n",
    "        plt.scatter(X_2d[j, 0], X_2d[j, 1], label=index_to_token[j])\n",
    "        labels.append(index_to_token[j])\n",
    "        # Add words as annotations\n",
    "        plt.annotate(index_to_token[j],\n",
    "                     (X_2d[j, 0], X_2d[j, 1]),\n",
    "                     textcoords=\"offset points\",\n",
    "                     xytext=(0, 10),\n",
    "                     ha='center')\n",
    "    else:\n",
    "        plt.scatter(X_2d[j, 0], X_2d[j, 1])\n",
    "\n",
    "plt.legend(labels, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ],
   "id": "2ce8bea3062932f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Perplexity\n",
    "Perplexity is a measurement used to evaluate the effectiveness of language models or probability models. It provides an indication of how well a model predicts a sample of data or the likelihood of an unseen event. Perplexity is commonly used in natural language processing tasks, such as machine translation, speech recognition, and language generation.\n",
    "\n",
    "Perplexity is derived from the concept of cross-entropy loss, which measures the dissimilarity between predicted probabilities and actual probabilities.\n",
    "\n",
    "$$\\text{Cross-Entropy Loss} = -\\sum_{i=1}^{N} y_i \\ln(p_i)$$\n",
    "The cross-entropy loss is calculated by taking the negative sum of the products of the true labels $y_i$ and the logarithm of the predicted probabilities $p_i$ over $N$ classes.\n",
    "\n",
    "Taking the exponential of the mean cross-entropy loss gives us the perplexity value.\n",
    "\n",
    "$$\\text{Perplexity} = e^{\\frac{1}{N} \\text{Cross-Entropy Loss}}$$\n",
    "\n",
    "\n",
    "A lower perplexity value indicates that the model is more confident and accurate in predicting the data. Conversely, a higher perplexity suggests that the model is less certain and less accurate in its predictions.\n",
    "\n",
    "Perplexity can be seen as an estimate of the average number of choices the model has for the next word or event in a sequence. A lower perplexity means that the model is more certain about the next word, while a higher perplexity means that there are more possible choices.\n"
   ],
   "id": "cecbc743b7e510a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for (my_loss, model_name)in zip(my_loss_list,[\"2-gram\",\"4-gram\",\"8-gram\"]):\n",
    "    # Calculate perplexity using the loss\n",
    "    perplexity = np.exp(my_loss)\n",
    "    plt.plot(perplexity,label=\"Perplexity - {}\".format(model_name))\n",
    "    plt.legend()"
   ],
   "id": "994f057c73f57f89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
